<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default"></script>

## Deep Networks with Stochastic Depth

* [paper](paper/30.001-16-Deep-Networks-with-Stochastic-Depth.pdf)

### 出发点
    
* 深度网络三个问题：

1. 反向传播的梯度消失
2. 减少前向传播中的特征重用
   * 输入实例的特征或者早期层建立的被清洗在不断权值乘法中，
3. 长训练时间

### 网络

* ResNet的block

  ![1540188178619](readme/30.001-resnet_block.png)

* 我们随机深度而不是宽度；

* 模块公式：
![1540189020417](readme/30.001-模块公式.png)

#### 每一层留下的概率：

![1540189467782](readme/30.001-每一层留下的概率.png)

 * 低层提取低水平特征将之后被高层使用，因此更应该留下来

 * \\( {{\rm{P}}_L} \\)的选择：

   ![1540190442325](readme/30.001-PL的选择.png)

* 深度的期望：

  ![1540190778812](readme/30.001-深度的期望.png)

* 测试阶段的方程：

  ![1540218823460](readme/30.001-测试时函数.png)
