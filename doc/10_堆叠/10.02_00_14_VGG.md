* [paper](/paper/10.02_00_14_Very_deep_convolutional_networks_for_large_scale_image_recognition.pdf)

![](/readme/10.02_00_vgg_01.png)
* 核心观点
    * 仅仅使用3x3 卷积核，作者认为组合2个 3x3 卷积层和5x5核具有一样的感受野。这使得卷积核尺寸表现，感受野不变。
    一个好处是减少了参数量。
    * 随着输入空间尺寸的变小，通道数不断加大
    * 每次池化之后都是用多个卷积层，这诠释了空间尺度缩小的时候，深度加深。
    * 在训练过程中使用scale jittering作为一种数据增强技术。
    * 使用每个卷积层后使用ReLU层并且通过 batch gradient descent训练。
* 比其他网络表现力更强，与gooleNet相比，网络架构更简单。
* 3*3网络的优势：
    1. 每一个卷积后面接ReLU，这样更加非线性
    2. 参数量少 3个3x3的卷积相当于一个7x7的卷积，感受野相同。
* 可以试着实现一些trick
    1. momentum SGD 0.9
    2. weight decay L2 * 5e-4
    3. drop out 0.5
    4. learning rate = 1e-2, 当验证集准确度不在提升时，衰减10， 衰减3次
    5. 初始化方式，预训练
* 初始化策略
    * 可以在一个小的网络上训练然后初始化
    * 训练11层的网络，然后利用11层的网络初始化相应的16层的网络
    * 可以利用256的数据训练，然后初始化384数据的网络
    
* [大话CNN经典模型：VGGNet](https://my.oschina.net/u/876354/blog/1634322)