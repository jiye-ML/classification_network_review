- [paper](paper/60.006-19-HetConv--Heterogeneous-Kernel-Based-Convolutions-for-Deep-CNNs.pdf)

## when

- CVPR 2019

## what

- 对于深度卷积神经网络而言，准确度和计算成本往往难以得兼，研究界也一直在探索通过模型压缩或设计新型高效架构来解决这一问题。印度理工学院坎普尔分校的一篇 CVPR 论文则给出了一个新的思路——使用异构的卷积过滤器；实验表明这种方法能在保证准确度的同时显著降低计算成本。 

### who （动机）

- 卷积神经网络（CNN）在视觉和自然语言处理领域都已经取得了卓越的表现。进一步提升性能的总体趋势使得模型越来越复杂且越来越深。但是，使用更深度的网络，通过提升模型复杂度来提升准确度并不是毫无代价的——计算成本（FLOPs）会大幅增长。因此，为了降低 FLOPs 以让模型更高效，研究者们已经提出了各种不同类型的卷积运算/卷积过滤器。
- 已有的卷积过滤器大致可以分为三类：
  - 1）深度方面的卷积过滤器，用于执行逐深度的卷积（DWC）[38]；
  - 2）点方面的卷积过滤器，用于执行逐点卷积（PWC）[36]；
  - 3）分组方面的卷积过滤器，用于执行逐分组卷积（GWC）[19]。
- 近来的大多数架构都使用了这些卷积过滤器的组合来得到高效的模型。很多常见的模型也使用了这些卷积（比如 DWC、PWC 和 GWC）来探索可以降低 FLOPs 的新架构。但是，设计一种新架构需要大量研究工作才能找到最优的过滤器组合，进而使得 FLOPs 最小。
- 另一种提升模型效率的常用方法是压缩模型。模型压缩大致可以分为三类：连接[剪枝](https://www.linkresearcher.com/theses/791542a6-fc00-4d00-b670-851994e441cc) [6]、过滤器剪枝 [24, 11, 21, 10, 32, 31, 33] 和量化 [6, 27]。
  - 过滤器剪枝的思想是将模型中贡献最小的过滤器剪枝掉，在移除这个过滤器/连接之后，模型通常还会得到微调以维持其性能。在给模型剪枝时，我们需要一个预训练模型（可能需要计算成本很高的训练作为预处理步骤），然后我们再丢弃贡献最小的过滤器。因此这是一个成本很高且很困难的过程。因此，比起剪枝，使用高效的卷积过滤器或卷积运算来设计高效的架构才是更常用的方法。这不需要昂贵的训练，然后在训练后进行剪枝，因为训练是从头开始高效完成的。
- 使用高效的卷积过滤器会有两种不同的目标。
  - 一类研究的重心是设计 FLOPs 最小的架构，同时会在准确度上妥协。这些研究的目标是为物联网/低端设备开发模型。这类模型有准确度较低的问题，因此必须搜索最佳可能的模型来实现准确度和 FLOPs 之间的平衡。因此这类模型在 FLOPs 和准确度之间会有所权衡。
  - 另一类研究则专注于在保证模型的 FLOPs 与原架构相同的同时提升准确度。Inception [35]、RexNetXt [40] 和 Xception [2] 等近期架构就属于这一类。他们的目标是使用高效的卷积过滤器设计一种更加复杂的模型，同时保持其 FLOPs 与基础模型一样。通常可以预期更复杂的模型能学习到更好的特征，从而得到更优的准确度。但是，这类模型的重点不是设计一种新架构，而主要是在标准的基础架构中使用已有的高效过滤器。因此这些工作会保持层的数量与架构和基础模型一样，再在每层上添加过滤器以使得 FLOPs 不增大。
- 不同于这两类方法，我们的方法主要侧重于通过设计新的卷积核（kernel）来降低给定模型/架构的 FLOPs，同时无损准确度。通过实验我们发现我们提出的方法的 FLOPs 比当前最佳的剪枝方法显著更低，同时还能维持基础模型/架构的准确度。而该剪枝方法则成本高昂，在实现 FLOPs 压缩时会导致准确度显著下降。
- 在我们提出的方法中，我们选择了一种不同的策略来提升已有模型的效率，同时不牺牲其准确度。架构搜索方法需要数年的研究才能得到一种最优化的架构。因此，我们没有去设计一种新的高效架构，而是设计了一种高效的卷积运算（卷积过滤器），并可直接用在任意已有的标准架构中来降低 FLOPs。为了实现这一目标，我们提出了一种新型的卷积——异构卷积（HetConv）。

## where

### 创新点

- 文章提出的“Heterogeneous Convolution”，顾名思义，就是卷积核的尺寸大小不一。比如在有256个通道的卷积核中，一部分kernel size为1，另一部分kernel size为3。
- HetConv带来的好处是可以无缝替换VGG、ResNet、MobileNet等结构的卷积形式，这种新的卷积形式，可以向标准卷积一样，从新开始训练，得到比pruning更好的性能效果。文章还指出，HetConv与标准卷积一样，实现latency zero。

![v2-e7b98450b01cadb302047717410b443f_hd](readme/60.006-19-HetConv--Heterogeneous-Kernel-Based-Convolutions-for-Deep-CNNs-形式.png)

### 贡献

* 我们设计了一种高效的异构卷积过滤器，可用在任何已有架构中，能在不牺牲准确度的同时提升这些架构的效率（将 FLOPs 降低 3 到 8 倍）。

* 我们提出的 HetConv 过滤器是按零延迟的方式设计的。因此，从输入到输出的延迟可忽略不计。

## how

* HetConvolution的方式很简单，就是将一部分卷积核尺寸设置为K，另一部分设置为1。更直观的可以看下图。

![v2-e77782009aa2b3b90de7bd4d7ff16f3d_hd](readme/60.006-19-HetConv--Heterogeneous-Kernel-Based-Convolutions-for-Deep-CNNs-卷积形式.png)



### 1. 网络结构

![image-20190526153456594](readme/60.006-19-HetConv--Heterogeneous-Kernel-Based-Convolutions-for-Deep-CNNs-网络结构-不同P值.png)

#### 1.2 第L层的网络

![image-20190526153543592](readme/60.006-19-HetConv--Heterogeneous-Kernel-Based-Convolutions-for-Deep-CNNs-网络结构-第L层.png)

### 2. 计算量的分析：

**[标准卷积】**计算量： ![FL_S=D_o \times D_o \times M\times N \times K \times K\rightarrow(1)](https://www.zhihu.com/equation?tex=FL_S%3DD_o+%5Ctimes+D_o+%5Ctimes+M%5Ctimes+N+%5Ctimes+K+%5Ctimes+K%5Crightarrow%281%29)

其中 ![D_o](https://www.zhihu.com/equation?tex=D_o) 是卷积输出特征图的尺寸，M是输入通道数，N是输出通道数，K是卷积核尺寸。

**HetConvolution：**假设输入通道数为M，有比例为P的卷积核尺寸为K，这样的kernel数为 ![\frac{M}{p}](https://www.zhihu.com/equation?tex=%5Cfrac%7BM%7D%7Bp%7D) ，其他都是![1 \times 1](https://www.zhihu.com/equation?tex=1+%5Ctimes+1)大小，这样的kernel数为 ![（1-\frac{1}{P}）\cdot M](https://www.zhihu.com/equation?tex=%EF%BC%881-%5Cfrac%7B1%7D%7BP%7D%EF%BC%89%5Ccdot+M) ，

那么 ![K \times K](https://www.zhihu.com/equation?tex=K+%5Ctimes+K) 卷积的计算量为：

![FL_K=(D_o \times D_o \times M \times N \times K \times K)/P](https://www.zhihu.com/equation?tex=FL_K%3D%28D_o+%5Ctimes+D_o+%5Ctimes+M+%5Ctimes+N+%5Ctimes+K+%5Ctimes+K%29%2FP)

![1 \times 1](https://www.zhihu.com/equation?tex=1+%5Ctimes+1) 卷积的计算量为：

![FL_1=（D_o \times D_o \times N）\times (1-\frac{1}{P}) \times M](https://www.zhihu.com/equation?tex=FL_1%3D%EF%BC%88D_o+%5Ctimes+D_o+%5Ctimes+N%EF%BC%89%5Ctimes+%281-%5Cfrac%7B1%7D%7BP%7D%29+%5Ctimes+M)

因此总的计算量为：

![FL_{HC} = FL_K + FL_1\rightarrow(2)](https://www.zhihu.com/equation?tex=FL_%7BHC%7D+%3D+FL_K+%2B+FL_1%5Crightarrow%282%29)

HetConvolution**与标准卷积的计算量之比：**

![R_{HetConv} = \frac{FL_k+FL_1}{FL_S} = \frac{1}{P}+\frac{1-\frac{1}{p}}{K^2}\rightarrow(3)](https://www.zhihu.com/equation?tex=R_%7BHetConv%7D+%3D+%5Cfrac%7BFL_k%2BFL_1%7D%7BFL_S%7D+%3D+%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B1-%5Cfrac%7B1%7D%7Bp%7D%7D%7BK%5E2%7D%5Crightarrow%283%29)

当P=1时，HetConv变为标准卷积，计算量之比为1。

【DW+PW】计算量： ![FL_{MobNet} = D_o \times D_o \times M \times K \times K + D_o \times D_o \times M \times N\rightarrow(4)](https://www.zhihu.com/equation?tex=FL_%7BMobNet%7D+%3D+D_o+%5Ctimes+D_o+%5Ctimes+M+%5Ctimes+K+%5Ctimes+K+%2B+D_o+%5Ctimes+D_o+%5Ctimes+M+%5Ctimes+N%5Crightarrow%284%29)（原文有误）

DW+PW与标准卷积的计算量之比：

![R_{MobNet} = \frac{FL_{MobNet}}{FL_S} = \frac{D_o \times D_o \times M \times K \times K + D_o \times D_o \times M \times N}{D_o \times D_o \times M\times N \times K \times K}=\frac{1}{N}+\frac{1}{K^2}\rightarrow(5)](https://www.zhihu.com/equation?tex=R_%7BMobNet%7D+%3D+%5Cfrac%7BFL_%7BMobNet%7D%7D%7BFL_S%7D+%3D+%5Cfrac%7BD_o+%5Ctimes+D_o+%5Ctimes+M+%5Ctimes+K+%5Ctimes+K+%2B+D_o+%5Ctimes+D_o+%5Ctimes+M+%5Ctimes+N%7D%7BD_o+%5Ctimes+D_o+%5Ctimes+M%5Ctimes+N+%5Ctimes+K+%5Ctimes+K%7D%3D%5Cfrac%7B1%7D%7BN%7D%2B%5Cfrac%7B1%7D%7BK%5E2%7D%5Crightarrow%285%29)


由公式(3)可知，增大P，HetConv变为标准卷积，控制P的大小，可以控制accuracy和FLOPs。

极端情况下，P=M的时候，公式（3）和（5）：

![\frac{1}{M}+\frac{1-\frac{1}{M}}{K^2} <\frac{1}{M}+\frac{1}{K^2}\rightarrow(6)](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BM%7D%2B%5Cfrac%7B1-%5Cfrac%7B1%7D%7BM%7D%7D%7BK%5E2%7D+%3C%5Cfrac%7B1%7D%7BM%7D%2B%5Cfrac%7B1%7D%7BK%5E2%7D%5Crightarrow%286%29)

因此，MobileNet比HetConvolution计算量更大。

GW+PW】计算量： ![FL_G =(D_o \times D_o \times M \times N \times K \times K)/G+ D_o \times D_o \times M \times N \rightarrow(7)](https://www.zhihu.com/equation?tex=FL_G+%3D%28D_o+%5Ctimes+D_o+%5Ctimes+M+%5Ctimes+N+%5Ctimes+K+%5Ctimes+K%29%2FG%2B+D_o+%5Ctimes+D_o+%5Ctimes+M+%5Ctimes+N+%5Crightarrow%287%29)

与标准卷积的计算量之比：

![R_{Group} = \frac{FL_G}{FL_S} = \frac{1}{G} + \frac{1}{K^2} \rightarrow(8)](https://www.zhihu.com/equation?tex=R_%7BGroup%7D+%3D+%5Cfrac%7BFL_G%7D%7BFL_S%7D+%3D+%5Cfrac%7B1%7D%7BG%7D+%2B+%5Cfrac%7B1%7D%7BK%5E2%7D+%5Crightarrow%288%29)

由公式（3）和（8）可知，P=G的时候：

![\frac{1}{P}+\frac{1-\frac{1}{p}}{K^2} < \frac{1}{P} + \frac{1}{K^2}\rightarrow(9)](https://www.zhihu.com/equation?tex=%5Cfrac%7B1%7D%7BP%7D%2B%5Cfrac%7B1-%5Cfrac%7B1%7D%7Bp%7D%7D%7BK%5E2%7D+%3C+%5Cfrac%7B1%7D%7BP%7D+%2B+%5Cfrac%7B1%7D%7BK%5E2%7D%5Crightarrow%289%29)

HetConv的计算量比GW+PW更少。

### 3. 为什么保持 3x3的核

1. ensure that the ﬁlter does cover the spatial correlation on some channels
2. need not to have the same spatial correlation on all channels.



## how much

作者选取了VGG、ResNet、MobileNet等网络，通过在CIFAR-10、ImageNet数据集上的实验验证HetConv的有效性。

![image-20190525160451204](readme/60.006-19-HetConv--Heterogeneous-Kernel-Based-Convolutions-for-Deep-CNNs-实验结果.png)

### 不同p值的影响

![image-20190526153807277](readme/60.006-19-HetConv--Heterogeneous-Kernel-Based-Convolutions-for-Deep-CNNs-实验-不同p值.png)

## why （为什么好）

- 文章提出了一种新的卷积方式，通过计算FLOPs和实验证明，HetConv可以在更少计算量的上面取得更高的精度，文章也和model conpression进行了对比，从实验结果来看，效果也挺明显。HetConv可以和现有的网络结构结合，操作简单方便。

  对于HeConv的实用性方面可能还需要时间来证明，毕竟理论计算量和实际情况还是有些差距，另外作者没有在detection、segmentation任务做实验，但从分类任务来说，缺少一定的可信度。希望尽快有开源实现。

